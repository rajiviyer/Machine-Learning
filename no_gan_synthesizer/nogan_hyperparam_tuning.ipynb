{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from modules import utils, model, train\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.core.common.random_state(None)\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (3554, 37)\n",
      "Training Shape: (1777, 37)\n",
      "Validation Shape: (1777, 37)\n"
     ]
    }
   ],
   "source": [
    "data = utils.get_cleaned_students_data()\n",
    "data = data.drop(data[data[\"curricular_units_2nd_sem_grade\"] == 0].index)\n",
    "\n",
    "target_column = 'target'\n",
    "\n",
    "training_data, validation_data = \\\n",
    "          utils.stratified_train_test_split(data,\n",
    "                                            target_column = target_column,\n",
    "                                            train_size=0.5,\n",
    "                                            random_state = seed\n",
    "                                            )\n",
    "\n",
    "print(f\"Data Shape: {data.shape}\\nTraining Shape: {training_data.shape}\\nValidation Shape: {validation_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1,3, figsize=(10,4), sharex=True, sharey=True)\n",
    "# orig_label = data[target_column].value_counts(normalize = True).reset_index()\n",
    "# tr_label = training_data[target_column].value_counts(normalize = True).reset_index()\n",
    "# val_label = validation_data[target_column].value_counts(normalize = True).reset_index()\n",
    "# sns.barplot(data = orig_label, x = \"target\", y = \"proportion\", ax = ax[0])\n",
    "# ax[0].set_title(\"original\")\n",
    "# sns.barplot(data = tr_label, x = \"target\", y = \"proportion\",  ax = ax[1], label = \"train\")\n",
    "# ax[1].set_title(\"train\")\n",
    "# sns.barplot(data = val_label, x = \"target\", y = \"proportion\", ax = ax[2], label = \"validation\")\n",
    "# ax[2].set_title(\"validation\")\n",
    "# plt.suptitle(\"Percentage plots of Target column\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(grid_range, features):\n",
    "    if len(features) != 2:\n",
    "        raise ValueError(\"Features should be of length 2!!\")\n",
    "    \n",
    "    b1_min = grid_range[0][0]\n",
    "    b1_max = grid_range[0][1]\n",
    "    b2_min = grid_range[1][0]\n",
    "    b2_max = grid_range[1][1]\n",
    "    b1_step = (b1_max - b1_min)/10\n",
    "    b2_step = (b2_max - b2_min)/10\n",
    "    min_delta = 999999999.9\n",
    "    test_count = 1\n",
    "\n",
    "    nogan = model.NoGANSynth(training_data[features])        \n",
    "    for b1 in np.arange(b1_min, b1_max, b1_step):\n",
    "        for b2 in np.arange(b2_min, b2_max, b2_step):\n",
    "            bins = [b2, b2]\n",
    "            _, results = \\\n",
    "                    train.nogan_synth(nogan, training_data[features], \n",
    "                                        validation_data[features], bins = bins,\n",
    "                                        n_nodes = 1000, verbose = False, \n",
    "                                        random_seed = seed)\n",
    "             \n",
    "            if test_count % 10 == 0:\n",
    "                print(f\"Test {test_count} completed!!!\")\n",
    "            test_count += 1\n",
    "        ks_stat = results[\"synth_comparison\"][\"ks_stat\"]\n",
    "        target_ks_stat = results[\"train_comparison\"][\"ks_stat\"]\n",
    "        delta = np.sqrt((ks_stat-target_ks_stat)**2)\n",
    "        if delta < min_delta:\n",
    "            best_b1 = b1\n",
    "            best_b2 = b2\n",
    "            min_delta = delta\n",
    "            best_ks_stat = ks_stat\n",
    "            best_target_ks_stat = target_ks_stat\n",
    "                    \n",
    "    return best_b1, best_b2, best_ks_stat, best_target_ks_stat, delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def grid_search_single(column_name, start, stop, step):    \n",
    "    nogan = model.NoGANSynth(training_data[[column_name]])\n",
    "    test_count = 1\n",
    "    min_delta = 999999999.9 \n",
    "    for p in tqdm(np.arange(start, stop+1, step)):\n",
    "        bins = [p]\n",
    "        _, results = \\\n",
    "                train.nogan_synth(nogan, training_data[[column_name]], \n",
    "                                validation_data[[column_name]], bins = bins,\n",
    "                                n_nodes = 1000, verbose = False, \n",
    "                                random_seed = seed)\n",
    "        test_count += 1\n",
    "        ks_stat = results[\"synth_comparison\"][\"ks_stat\"]\n",
    "        target_ks_stat = results[\"train_comparison\"][\"ks_stat\"]\n",
    "        delta = np.sqrt((ks_stat-target_ks_stat)**2)  \n",
    "        if delta < min_delta:\n",
    "            best_p = p\n",
    "            min_delta = delta\n",
    "            best_ks_stat = ks_stat\n",
    "            best_target_ks_stat = target_ks_stat\n",
    "    print(f\"best_bin: {best_p}\\nbest_ks_stat: {best_ks_stat}\\nbest_target_ks_stat: {best_target_ks_stat}\\nmin_delta: {min_delta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:36<00:00,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_bin: 131\n",
      "best_ks_stat: 0.12492965672481715\n",
      "best_target_ks_stat: 0.033764772087788386\n",
      "min_delta: 0.09116488463702876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "grid_search_single(\"course\", 1, 500, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def hyperparameter_tuning(features:List, b1:int = 100, b2:int = 100, \n",
    "                          step_b1:int = 100, step_b2:int = 100, \n",
    "                          iter:int = 3):\n",
    "  final_min_delta = 999999999.9\n",
    "  start_time = timer()\n",
    "  for level in range(iter):\n",
    "      step_b1 /= 2\n",
    "      step_b2 /= 2\n",
    "      b1_min = max(0, b1 - step_b1)\n",
    "      b1_max = b1 + step_b1\n",
    "      b2_min = b2 - step_b2\n",
    "      b2_max = b2 + step_b2\n",
    "      grid_range = [(b1_min, b1_max),(b2_min, b2_max)]\n",
    "      (b1, b2, ks_stat, target_ks_stat, min_delta) = \\\n",
    "                              grid_search(grid_range, features)\n",
    "      print(f\"b1: {b1}, b2: {b2}, ks_stat: {ks_stat}, target_ks_stat: {target_ks_stat}, min_delta: {min_delta}\")\n",
    "                              \n",
    "      if min_delta < final_min_delta:\n",
    "        final_min_delta = min_delta\n",
    "        final_best_b1 = b1\n",
    "        final_best_b2 = b2\n",
    "        final_ks_stat = ks_stat\n",
    "        final_target_ks_stat =  target_ks_stat\n",
    "  end_time = timer()\n",
    "  print(f\"final_b1: {final_best_b1}\\nfinal_b2: {final_best_b2}\\nfinal_ks_stat: {final_ks_stat}\\nfinal_target_ks_stat: {final_target_ks_stat}\\nfinal_min_delta: {min_delta}\\nTotal Time: {end_time-start_time:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 10 completed!!!\n",
      "Test 20 completed!!!\n",
      "Test 30 completed!!!\n",
      "Test 40 completed!!!\n",
      "Test 50 completed!!!\n",
      "Test 60 completed!!!\n",
      "Test 70 completed!!!\n",
      "Test 80 completed!!!\n",
      "Test 90 completed!!!\n",
      "Test 100 completed!!!\n",
      "b1: 50.0, b2: 140.0, ks_stat: 0.22172200337647718, target_ks_stat: 0.03545301069217782, min_delta: 0.18626899268429936\n",
      "Test 10 completed!!!\n",
      "Test 20 completed!!!\n",
      "Test 30 completed!!!\n",
      "Test 40 completed!!!\n",
      "Test 50 completed!!!\n",
      "Test 60 completed!!!\n",
      "Test 70 completed!!!\n",
      "Test 80 completed!!!\n",
      "Test 90 completed!!!\n",
      "Test 100 completed!!!\n",
      "b1: 25.0, b2: 160.0, ks_stat: 0.22172200337647718, target_ks_stat: 0.03545301069217782, min_delta: 0.18626899268429936\n",
      "Test 10 completed!!!\n",
      "Test 20 completed!!!\n",
      "Test 30 completed!!!\n",
      "Test 40 completed!!!\n",
      "Test 50 completed!!!\n",
      "Test 60 completed!!!\n",
      "Test 70 completed!!!\n",
      "Test 80 completed!!!\n",
      "Test 90 completed!!!\n",
      "Test 100 completed!!!\n",
      "b1: 12.5, b2: 170.0, ks_stat: 0.22172200337647718, target_ks_stat: 0.03545301069217782, min_delta: 0.18626899268429936\n",
      "final_b1: 50.0\n",
      "final_b2: 140.0\n",
      "final_ks_stat: 0.22172200337647718\n",
      "final_target_ks_stat: 0.03545301069217782\n",
      "final_min_delta: 0.18626899268429936\n",
      "Total Time: 2310.1169\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "  'course',\n",
    "  'unemployment_rate',\n",
    "    ]\n",
    "\n",
    "hyperparameter_tuning(features = features, b1 = 100, b2 = 100, \n",
    "                      step_b1 = 100, step_b2 = 100, \n",
    "                      iter = 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b1 = 100\n",
    "# b2 = 100\n",
    "# step_b1 = 100\n",
    "# step_b2 = 100\n",
    "# features = [\n",
    "#   'course',\n",
    "#   'unemployment_rate'\n",
    "#     ]\n",
    "# final_min_delta = 999999999.9\n",
    "# start_time = timer()\n",
    "# for level in range(3):\n",
    "#     step_b1 /= 2\n",
    "#     step_b2 /= 2\n",
    "#     b1_min = max(0, b1 - step_b1)\n",
    "#     b1_max = b1 + step_b1\n",
    "#     b2_min = b2 - step_b2\n",
    "#     b2_max = b2 + step_b2\n",
    "#     grid_range = [(b1_min, b1_max),(b2_min, b2_max)]\n",
    "#     (b1, b2, ks_stat, target_ks_stat, min_delta) = \\\n",
    "#                             hyperparameter_search(grid_range, features)\n",
    "#     print(f\"b1: {b1}, b2: {b2}, ks_stat: {ks_stat}, target_ks_stat: {target_ks_stat}, min_delta: {min_delta}\")\n",
    "                            \n",
    "#     if min_delta < final_min_delta:\n",
    "#       final_min_delta = min_delta\n",
    "#       final_best_b1 = b1\n",
    "#       final_best_b2 = b2\n",
    "#       final_ks_stat = ks_stat\n",
    "#       final_target_ks_stat =  target_ks_stat\n",
    "# end_time = timer()\n",
    "# print(f\"final_b1: {final_best_b1}\\nfinal_b2: {final_best_b2}\\nfinal_ks_stat: {final_ks_stat}\\nfinal_target_ks_stat: {final_target_ks_stat}\\nfinal_min_delta: {min_delta}\\nTotal Time: {end_time-start_time:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hyperparmeter_search(training_data,validation_data):\n",
    "#     opt_bins = {}\n",
    "#     for col in training_data.columns:\n",
    "#         nogan = model.NoGANSynth(training_data[[col]])\n",
    "#         p_min = 1\n",
    "#         p_max = 100\n",
    "#         p_step = (p_max - p_min)/10\n",
    "#         min_delta = 999999999.9\n",
    "#         print(f\"Column: {col}\")\n",
    "#         for p in np.arange(p_min, p_max, p_step):\n",
    "#             bins = [p]\n",
    "#             #print(f\"Bin Length: {len(bins)}, Col Count: {len(training_data.columns)}\")\n",
    "#             synth_data, results = \\\n",
    "#                         train.nogan_synth(nogan, training_data[[col]], \n",
    "#                                           validation_data[[col]], bins = bins,\n",
    "#                                           n_nodes = 1000, verbose = False, \n",
    "#                                           random_seed = seed)\n",
    "#             ks_stat = results[\"synth_comparison\"][\"ks_stat\"]\n",
    "#             target_ks_stat = results[\"train_comparison\"][\"ks_stat\"]\n",
    "#             delta = np.sqrt((ks_stat-target_ks_stat)**2)\n",
    "#             if delta < min_delta:\n",
    "#                 best_bin_val = p\n",
    "#                 min_delta = delta\n",
    "#                 best_ks_stat = ks_stat\n",
    "#                 best_target_ks_stat = target_ks_stat\n",
    "#         opt_bins[col] = {\"bin_val\":best_bin_val, \"ks_stat\":best_ks_stat,\n",
    "#                          \"target_ks_stat\":best_target_ks_stat, \"delta\":delta}  \n",
    "        \n",
    "#     return opt_bins\n",
    "#         # for i in range(3):\n",
    "            \n",
    "#         #     nogan = model.NoGANSynth(training_data[col])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = hyperparmeter_search(training_data,validation_data)\n",
    "\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = pd.DataFrame(results)\n",
    "\n",
    "# results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ round(bin) for bin in results_df.iloc[0,:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col = \"curricular_units_2nd_sem_approved\"\n",
    "# bin = [3]\n",
    "# len(bin), len(training_data[[col]].columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins = [40] * len(features)\n",
    "# nogan = model.NoGANSynth(training_data)\n",
    "# synth_data, results = train.nogan_synth(nogan, training_data, \n",
    "#                                         validation_data, bins = bins,\n",
    "#                                         n_nodes = 1000, verbose = False, \n",
    "#                                         random_seed = seed)\n",
    "\n",
    "# ks_stat = results[\"synth_comparison\"][\"ks_stat\"]\n",
    "# target_ks_stat = results[\"train_comparison\"][\"ks_stat\"]\n",
    "\n",
    "# print(f\"ks_stat: {ks_stat:.5f}\\ntarget_ks_stat: {target_ks_stat:.5f}\\nRoot Squared Diff {np.sqrt((ks_stat-target_ks_stat)**2):.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
