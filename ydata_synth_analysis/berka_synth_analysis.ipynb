{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "600e7a87-0ae0-4d7e-8f61-02a6dd5278e7",
   "metadata": {},
   "source": [
    "## Analysis of Synthetic Data Generated from the Berka Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93d010cc-bc20-4f51-a56e-94e7d12f0f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "import psycopg2\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from genai_evaluation import multivariate_ecdf, ks_statistic\n",
    "from nogan_synthesizer.preprocessing import wrap_category_columns, unwrap_category_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50b284d-521d-49c1-b94a-9433dd21852a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1480ed-4b1f-4712-9a3a-9f1aee7ad8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c6b1558-efe4-49e2-8c54-8fa8b0b099fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [\n",
    "    'account', \n",
    "    'card', \n",
    "    'client', \n",
    "    'disposition', \n",
    "    'district',\n",
    "    'loan', \n",
    "    'orders', \n",
    "    'transaction'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d2a0c9d-2dfa-4633-bf9e-dc71df949f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_primary_keys_issues(engine, schema):\n",
    "    try:\n",
    "        query = text(f\"\"\" \n",
    "        select 'account' table_name, count(distinct account_id) as count_dist_ids, count(*) as count_rows\n",
    "        from account\n",
    "        having count(distinct account_id) <> count(*)\n",
    "        union all \n",
    "        select 'card' table_name, count(distinct card_id) as count_dist_ids, count(*) as count_rows\n",
    "        from card\n",
    "        having count(distinct card_id) <> count(*)\n",
    "        union all \n",
    "        select 'client' table_name, count(distinct client_id) as count_dist_ids, count(*) as count_rows\n",
    "        from client\n",
    "        having count(distinct client_id) <> count(*)\n",
    "        union all \n",
    "        select 'disposition' table_name, count(distinct disposition_id) as count_dist_ids, count(*) as count_rows\n",
    "        from disposition\n",
    "        having count(distinct disposition_id) <> count(*)\n",
    "        union all \n",
    "        select 'district' table_name, count(distinct district_id) as count_dist_ids, count(*) as count_rows\n",
    "        from district\n",
    "        having count(distinct district_id) <> count(*)\n",
    "        union all \n",
    "        select 'loan' table_name, count(distinct loan_id) as count_dist_ids, count(*) as count_rows\n",
    "        from loan\n",
    "        having count(distinct loan_id) <> count(*)\n",
    "        union all \n",
    "        select 'orders' table_name, count(distinct orders_id) as count_dist_ids, count(*) as count_rows\n",
    "        from orders\n",
    "        having count(distinct orders_id) <> count(*)\n",
    "        union all \n",
    "        select 'transaction' table_name, count(distinct transaction_id) as count_dist_ids, count(*) as count_rows\n",
    "        from transaction\n",
    "        having count(distinct transaction_id) <> count(*)\n",
    "        \"\"\")\n",
    "        # print(query)\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(query)\n",
    "            columns = result.keys()\n",
    "            result_set = [{column: value for column, value in zip(columns, row)} for row in result]\n",
    "            return result_set\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def get_foreign_keys_issues(engine, schema):\n",
    "    try:\n",
    "        query = text(f\"\"\" \n",
    "            select 'account_district' table_mappings, count(*) record_count \n",
    "            \tfrom account where district_id not in (select district_id from district)\n",
    "            having count(*) > 0\n",
    "            union all\n",
    "            select 'client_district' table_mappings, count(*) record_count \n",
    "            \tfrom client where district_id not in (select district_id from district)\n",
    "            having count(*) > 0\t\n",
    "            union all\n",
    "            select 'disposition_account' table_mappings, count(*) record_count \n",
    "            \tfrom disposition where account_id not in (select account_id from account)\n",
    "            having count(*) > 0\t\n",
    "            union all\n",
    "            select 'transaction_account' table_mappings, count(*) record_count \n",
    "            \tfrom transaction where account_id not in (select account_id from account)\n",
    "            having count(*) > 0\t\n",
    "            union all\n",
    "            select 'loan_account' table_mappings, count(*) record_count \n",
    "            \tfrom loan where account_id not in (select account_id from account)\n",
    "            having count(*) > 0\t\n",
    "            union all\n",
    "            select 'orders_account' table_mappings, count(*) record_count \n",
    "            \tfrom orders where account_id not in (select account_id from account)\n",
    "            having count(*) > 0\t\n",
    "            union all\n",
    "            select 'disposition_client' table_mappings, count(*) record_count \n",
    "            \tfrom disposition where client_id not in (select client_id from client)\n",
    "            having count(*) > 0\t\n",
    "            union all\n",
    "            select 'card_disposition' table_mappings, count(*) record_count \n",
    "            \tfrom card where disposition_id not in (select disposition_id from disposition)\n",
    "            having count(*) > 0        \n",
    "        \"\"\")\n",
    "        # print(query)\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(query)\n",
    "            columns = result.keys()\n",
    "            result_set = [{column: value for column, value in zip(columns, row)} for row in result]\n",
    "            return result_set\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def get_constraints_count(engine, schema):\n",
    "    try:\n",
    "        query = text(f\"\"\" \n",
    "        select constraint_type, count(*) no_of_constraints from information_schema.table_constraints\n",
    "        where constraint_schema  = '{schema}' and constraint_type in ('PRIMARY KEY', 'FOREIGN KEY')\n",
    "        group by constraint_type\n",
    "        \"\"\")\n",
    "        # print(query)\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(query)\n",
    "            columns = result.keys()\n",
    "            result_set = [{column: value for column, value in zip(columns, row)} for row in result]\n",
    "            return result_set\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb0419eb-6f09-4e17-98a6-d14e7b5b9f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_DBUSER = \"genai_user\"\n",
    "SOURCE_DBPASSWD = \"welcome1\"\n",
    "SOURCE_DBHOST = \"217.76.56.228\"\n",
    "SOURCE_DBSCHEMA = \"berka_original\"\n",
    "SOURCE_DBNAME = \"genaidb\"\n",
    "SOURCE_DBCONN = f\"postgresql+psycopg2://{SOURCE_DBUSER}:{SOURCE_DBPASSWD}@{SOURCE_DBHOST}/{SOURCE_DBNAME}\"\n",
    "SOURCE_CONNECT_ARGS = {'options': '-csearch_path={}'.format(SOURCE_DBSCHEMA)}\n",
    "\n",
    "source_engine = create_engine(SOURCE_DBCONN, connect_args=SOURCE_CONNECT_ARGS)\n",
    "\n",
    "source_data = {}\n",
    "with source_engine.connect() as conn:\n",
    "    for table in tables:\n",
    "        source_data[table] = pd.read_sql_table(table_name = table, con =  conn, schema = SOURCE_DBSCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4a57d49-a779-4f47-846d-e2fbc2ca2a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYNTH_DBUSER = \"genai_user\"\n",
    "SYNTH_DBPASSWD = \"welcome1\"\n",
    "SYNTH_DBHOST = \"77.237.241.186\"\n",
    "SYNTH_DBNAME = \"genai_resultdb\"\n",
    "SYNTH_DBCONN = f\"postgresql+psycopg2://{SYNTH_DBUSER}:{SYNTH_DBPASSWD}@{SYNTH_DBHOST}/{SYNTH_DBNAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fa4268-fa97-434a-a6cf-11dc4aa41819",
   "metadata": {},
   "source": [
    "#### Gretel Connection & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "934681b1-b51a-4955-b0f0-7a718516f283",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRETEL_SYNTH_DBSCHEMA = \"berka_gretel\"\n",
    "GRETEL_SYNTH_CONNECT_ARGS = {'options': '-csearch_path={}'.format(GRETEL_SYNTH_DBSCHEMA)}\n",
    "gretel_engine = create_engine(SYNTH_DBCONN, connect_args=GRETEL_SYNTH_CONNECT_ARGS)\n",
    "\n",
    "gretel_synth_data = {}\n",
    "with gretel_engine.connect() as conn:\n",
    "    for table in tables:\n",
    "        gretel_synth_data[table] = pd.read_sql_table(table_name = table, con =  conn, schema = GRETEL_SYNTH_DBSCHEMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5d4822-4334-402e-9eaf-46602674fd99",
   "metadata": {},
   "source": [
    "#### MostlyAI Connection & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1697bab5-6394-4932-ab58-6a29d3d3dfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOSTLYAI_SYNTH_DBSCHEMA = \"berka_mostlyai\"\n",
    "MOSTLYAI_SYNTH_CONNECT_ARGS = {'options': '-csearch_path={}'.format(MOSTLYAI_SYNTH_DBSCHEMA)}\n",
    "mostlyai_engine = create_engine(SYNTH_DBCONN, connect_args=MOSTLYAI_SYNTH_CONNECT_ARGS)\n",
    "\n",
    "mostlyai_synth_data = {}\n",
    "with mostlyai_engine.connect() as conn:\n",
    "    for table in tables:\n",
    "        mostlyai_synth_data[table] = pd.read_sql_table(table_name = table, con =  conn, schema = MOSTLYAI_SYNTH_DBSCHEMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980c05a3-ac7b-47c1-a50a-055f39907a2e",
   "metadata": {},
   "source": [
    "#### YDATA Connection & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3922851-6982-4176-8b0a-1aaac30b3a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "YDATA_SYNTH_DBSCHEMA = \"berka_ydata\"\n",
    "YDATA_SYNTH_CONNECT_ARGS = {'options': '-csearch_path={}'.format(YDATA_SYNTH_DBSCHEMA)}\n",
    "ydata_engine = create_engine(SYNTH_DBCONN, connect_args=YDATA_SYNTH_CONNECT_ARGS)\n",
    "\n",
    "ydata_synth_data = {}\n",
    "with ydata_engine.connect() as conn:\n",
    "    for table in tables:\n",
    "        ydata_synth_data[table] = pd.read_sql_table(table_name = table, con =  conn, schema = YDATA_SYNTH_DBSCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01e4b875-ad74-417b-a2b0-e5a46e3a3151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Source Data Details ------\n",
      "account Shape: (4500, 4)\n",
      "card Shape: (892, 4)\n",
      "client Shape: (5369, 3)\n",
      "disposition Shape: (5369, 4)\n",
      "district Shape: (77, 16)\n",
      "loan Shape: (682, 7)\n",
      "orders Shape: (6471, 6)\n",
      "transaction Shape: (49498, 9)\n",
      "\n",
      "----- Gretel Synth Data Details ------\n",
      "account Shape: (4500, 4)\n",
      "card Shape: (892, 4)\n",
      "client Shape: (5369, 3)\n",
      "disposition Shape: (5369, 4)\n",
      "district Shape: (77, 16)\n",
      "loan Shape: (682, 7)\n",
      "orders Shape: (6471, 6)\n",
      "transaction Shape: (49498, 9)\n",
      "\n",
      "----- MostlyAI Synth Data Details ------\n",
      "account Shape: (3960, 4)\n",
      "card Shape: (616, 4)\n",
      "client Shape: (6299, 3)\n",
      "disposition Shape: (4730, 4)\n",
      "district Shape: (77, 16)\n",
      "loan Shape: (816, 7)\n",
      "orders Shape: (7823, 6)\n",
      "transaction Shape: (43560, 9)\n",
      "\n",
      "----- YData Synth Data Details ------\n",
      "account Shape: (3908, 4)\n",
      "card Shape: (892, 4)\n",
      "client Shape: (5413, 3)\n",
      "disposition Shape: (5369, 4)\n",
      "district Shape: (77, 16)\n",
      "loan Shape: (90, 7)\n",
      "orders Shape: (5404, 6)\n",
      "transaction Shape: (42986, 9)\n"
     ]
    }
   ],
   "source": [
    "print(\"----- Source Data Details ------\")\n",
    "for table in tables:\n",
    "    print(f\"{table} Shape: {source_data[table].shape}\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"----- Gretel Synth Data Details ------\")\n",
    "for table in tables:\n",
    "    print(f\"{table} Shape: {gretel_synth_data[table].shape}\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"----- MostlyAI Synth Data Details ------\")\n",
    "for table in tables:\n",
    "    print(f\"{table} Shape: {mostlyai_synth_data[table].shape}\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"----- YData Synth Data Details ------\")\n",
    "for table in tables:\n",
    "    print(f\"{table} Shape: {ydata_synth_data[table].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91539a5d-2307-4247-8f47-2fd94184823d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  constraint_type  no_of_constraints\n",
      "0     FOREIGN KEY                  8\n",
      "1     PRIMARY KEY                  8\n",
      "Total Constraints: 16\n"
     ]
    }
   ],
   "source": [
    "constraints = get_constraints_count(source_engine, SOURCE_DBSCHEMA)\n",
    "if constraints:\n",
    "    # print(constraints)\n",
    "    constraints_df = pd.DataFrame(constraints)\n",
    "    print(constraints_df.head())\n",
    "    total_constraints = constraints_df.no_of_constraints.sum()\n",
    "else:\n",
    "    total_constraints = 0\n",
    "\n",
    "print(f\"Total Constraints: {total_constraints}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8912e4-83d8-4cb1-9f02-5f5867ea6bc0",
   "metadata": {},
   "source": [
    "### Gretel Preprocess Categorical Columns for table account"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bca6dc-578d-47d4-8e25-9a188a15b5af",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7293ef87-9514-4c30-a7ce-ba5595fc331d",
   "metadata": {},
   "source": [
    "#### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "603a8361-6209-4dc4-9fb1-157a610fb1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date', 'type', 'operation', 'amount', 'balance', 'k_symbol', 'bank']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = source_data[table].columns\n",
    "[col for col in cols if not col.endswith('_id')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bde4803c-e2c1-4884-8095-face4e378e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.core.common.random_state(None)\n",
    "seed = 1047\n",
    "ks_seed = 1034"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1139aa38-c84a-48f2-a53b-90518079d9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_synth(synth_solution, original_data, synth_data, tables,\n",
    "                   original_data_engine, synth_data_engine, total_constraints,\n",
    "                   synth_dbschema, verbose = False\n",
    "                  ):\n",
    "    ## Data Integrity\n",
    "    if verbose:\n",
    "        print(f\"---------{synth_solution} Evaluation-----------\")\n",
    "        print(f\"{synth_solution} Constraint Issues Details\")\n",
    "    primary_keys_issues = get_primary_keys_issues(synth_data_engine, synth_dbschema)\n",
    "    if verbose and primary_keys_issues:\n",
    "        print(f\"Primary Key Issues: {primary_keys_issues}\")\n",
    "    primary_keys_issue_count = len(primary_keys_issues)\n",
    "\n",
    "    foreign_keys_issues = get_foreign_keys_issues(synth_data_engine, synth_dbschema)\n",
    "    if verbose and primary_keys_issues:\n",
    "        print(f\"Foreign Key Issues: {foreign_keys_issues}\")    \n",
    "    foreign_keys_issue_count = len(foreign_keys_issues)\n",
    "    data_integrity_score = 1 - ((primary_keys_issue_count + foreign_keys_issue_count)/total_constraints)\n",
    "    if verbose:\n",
    "        print(f\" -Primary Keys Issues Count: {primary_keys_issue_count}\")\n",
    "        print(f\" -Foreign Keys Issues Count: {foreign_keys_issue_count}\")\n",
    "        print(f\" -Data Integrity Score: {data_integrity_score}\")\n",
    "\n",
    "    genai_eval_scores = []\n",
    "    for table in tables:\n",
    "        # print(table)\n",
    "        orig_df = original_data[table]\n",
    "        synth_df = synth_data[table]\n",
    "\n",
    "        # Remove id columns\n",
    "        non_id_cols = [col for col in orig_df.columns if not col.endswith('_id')]\n",
    "        orig_df = orig_df[non_id_cols]\n",
    "        synth_df = synth_df[non_id_cols]\n",
    "        cat_columns = orig_df.select_dtypes(exclude=[\"number\",\"bool_\",\"datetime64[ns]\"]).columns.tolist()\n",
    "        # cat_columns = [col for col in cat_columns if not col.endswith('_id')]\n",
    "        # print(cat_columns)\n",
    "        date_columns = orig_df.select_dtypes(include=[\"datetime64[ns]\"]).columns.tolist()\n",
    "        if date_columns:\n",
    "            orig_df = orig_df.drop(date_columns, axis = 1)\n",
    "            synth_df = synth_df.drop(date_columns, axis = 1)\n",
    "        \n",
    "        # Encode Category Columns\n",
    "        if cat_columns:\n",
    "            wrapped_orig, idx_to_key_orig, key_to_idx_orig = wrap_category_columns(orig_df,cat_columns)\n",
    "            wrapped_synth, idx_to_key_synth, key_to_idx_synth = wrap_category_columns(synth_df,cat_columns)\n",
    "        else:\n",
    "            wrapped_orig = orig_df\n",
    "            wrapped_synth = synth_df\n",
    "        # Calculate ECDF\n",
    "        if verbose:\n",
    "            print(\"----Calculating ECDF------\")\n",
    "        query_orig, ecdf_orig, ecdf_synth = \\\n",
    "            multivariate_ecdf(wrapped_orig, \n",
    "                              wrapped_synth, \n",
    "                              n_nodes = 3000, \n",
    "                              verbose = verbose,\n",
    "                              random_seed=ks_seed) \n",
    "\n",
    "        # Calculate KS Stat\n",
    "        ks_stat = ks_statistic(ecdf_orig, ecdf_synth)\n",
    "        \n",
    "        genai_eval_scores.append({\"table\":table, \"eval_score\": ks_stat})\n",
    "    return {\"data_integrity_score\": data_integrity_score, \"eval_scores\": genai_eval_scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "734e5282-9f18-4fc3-965f-26fb05668e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gretel_results = evaluate_synth(synth_solution = \"gretel\", original_data = source_data, \n",
    "                                synth_data = gretel_synth_data, tables = tables, original_data_engine = source_engine, \n",
    "                                synth_data_engine = gretel_engine, total_constraints = total_constraints,\n",
    "                                synth_dbschema = GRETEL_SYNTH_DBSCHEMA, verbose=False)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dae5a0b3-f52c-4fe2-aaf5-77fda045165d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gretel Data Integrity Score: 1.0\n",
      "Gretel GenAI Eval Score: 0.270\n"
     ]
    }
   ],
   "source": [
    "print(f\"Gretel Data Integrity Score: {gretel_results['data_integrity_score']}\")\n",
    "print(f\"Gretel GenAI Eval Score: {pd.DataFrame(gretel_results['eval_scores']).eval_score.median():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddd36474-9991-4163-adf0-3eb92993994a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MostlyAI Data Integrity Score: 1.0\n",
      "MostlyAI GenAI Eval Score: 0.314\n"
     ]
    }
   ],
   "source": [
    "mostlyai_results = evaluate_synth(synth_solution = \"mostlyai\", original_data = source_data, \n",
    "                                  synth_data = mostlyai_synth_data, tables = tables,\n",
    "                                  original_data_engine = source_engine, synth_data_engine = mostlyai_engine, \n",
    "                                  total_constraints = total_constraints,\n",
    "                                  synth_dbschema = MOSTLYAI_SYNTH_DBSCHEMA, verbose=False)\n",
    "print(f\"MostlyAI Data Integrity Score: {mostlyai_results['data_integrity_score']}\")\n",
    "print(f\"MostlyAI GenAI Eval Score: {pd.DataFrame(mostlyai_results['eval_scores']).eval_score.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "499c0eb2-8300-4d70-bd70-3090314b4bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YData Data Integrity Score: 1.0\n",
      "YData GenAI Eval Score: 0.160\n"
     ]
    }
   ],
   "source": [
    "ydata_results = evaluate_synth(synth_solution = \"ydata\", original_data = source_data, \n",
    "                               synth_data = ydata_synth_data, tables = tables,\n",
    "                               original_data_engine = source_engine, synth_data_engine = ydata_engine, \n",
    "                               total_constraints = total_constraints,\n",
    "                               synth_dbschema = YDATA_SYNTH_DBSCHEMA, verbose=False)\n",
    "print(f\"YData Data Integrity Score: {ydata_results['data_integrity_score']}\")\n",
    "print(f\"YData GenAI Eval Score: {pd.DataFrame(ydata_results['eval_scores']).eval_score.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a40e1a47-188e-492a-9328-519b4313bd55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>synth_time</th>\n",
       "      <th>data_integrity_score</th>\n",
       "      <th>genai_eval_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gretel</td>\n",
       "      <td>40 mins</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mostly AI</td>\n",
       "      <td>2 mins</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YData AI</td>\n",
       "      <td>7 mins</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      method synth_time  data_integrity_score  genai_eval_score\n",
       "0     Gretel    40 mins                   1.0              0.28\n",
       "1  Mostly AI     2 mins                   1.0              0.31\n",
       "2   YData AI     7 mins                   1.0              0.16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gretel_synth_time = \"40 mins\"\n",
    "mostlyai_synth_time = \"2 mins\"\n",
    "ydata_synth_time = \"7 mins\"\n",
    "results = [\n",
    "    {\"method\": \"Gretel\", \"synth_time\": gretel_synth_time, \n",
    "     \"data_integrity_score\": gretel_results['data_integrity_score'], \n",
    "     \"genai_eval_score\": pd.DataFrame(gretel_results['eval_scores']).eval_score.mean().round(2)},\n",
    "    {\"method\": \"Mostly AI\", \"synth_time\": mostlyai_synth_time, \n",
    "     \"data_integrity_score\": mostlyai_results['data_integrity_score'], \n",
    "     \"genai_eval_score\": pd.DataFrame(mostlyai_results['eval_scores']).eval_score.mean().round(2) },\n",
    "    {\"method\": \"YData AI\", \"synth_time\": ydata_synth_time, \n",
    "     \"data_integrity_score\": ydata_results['data_integrity_score'], \n",
    "     \"genai_eval_score\": pd.DataFrame(ydata_results['eval_scores']).eval_score.mean().round(2) }  \n",
    "]\n",
    "\n",
    "pd.DataFrame(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ydata",
   "language": "python",
   "name": "ydata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
