{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c259dec3-94a5-4471-bd49-bd3405369d26",
   "metadata": {},
   "source": [
    "## Analysis of Synthetic Data Generated from the Berka Dataset\n",
    "#### Make sure the main directory structure and files are downloaded locally into directory called berka_results\n",
    "#### Link: https://drive.google.com/drive/folders/12OvCmPUDUtffQnu_ZiCQ4SWjPL3i0kvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edd40aad-fab1-490c-9f66-7ddcb3d88aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "import psycopg2\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from genai_evaluation import multivariate_ecdf, ks_statistic\n",
    "from nogan_synthesizer.preprocessing import wrap_category_columns, unwrap_category_columns\n",
    "import os\n",
    "from pandasql import sqldf\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24e9e2c4-5be3-487d-abe8-74134ff35d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_DIR = \"./berka_results\"\n",
    "ORIG_DIR = f\"{DATASETS_DIR}/original\"\n",
    "GRETEL_DIR = f\"{DATASETS_DIR}/gretel\"\n",
    "YDATA_DIR = f\"{DATASETS_DIR}/ydata\"\n",
    "MOSTLYAI_DIR = f\"{DATASETS_DIR}/mostlyai\"\n",
    "SDV_DIR = f\"{DATASETS_DIR}/sdv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbf58e79-5d99-4c70-92e6-0d6abe51ed8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_files(directory):\n",
    "    csv_dict = {}\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                filename_without_extension = os.path.splitext(file)[0]\n",
    "                df = pd.read_csv(file_path, parse_dates=True)\n",
    "                csv_dict[filename_without_extension] = df\n",
    "    return csv_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de2ce5d-b77b-48e7-b068-5e82fa4520b0",
   "metadata": {},
   "source": [
    "#### Read Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29e2fd12-a1c6-493d-ab26-4a056e73ba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Original\n",
    "orig_data = read_csv_files(ORIG_DIR)\n",
    "\n",
    "## Gretel\n",
    "gretel_synth_data = read_csv_files(GRETEL_DIR)\n",
    "\n",
    "## Mostly AI\n",
    "mostlyai_synth_data = read_csv_files(MOSTLYAI_DIR)\n",
    "\n",
    "## SDV \n",
    "sdv_synth_data = read_csv_files(SDV_DIR)\n",
    "\n",
    "## YData\n",
    "ydata_synth_data = read_csv_files(YDATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ce8110a-6cd8-4b74-aac2-6a6dad477782",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [\n",
    "    'account', \n",
    "    'card', \n",
    "    'client', \n",
    "    'disposition', \n",
    "    'district',\n",
    "    'loan', \n",
    "    'orders', \n",
    "    'transaction'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "612ab989-26e8-4d70-8937-77733cc1bf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Original Data Details ------\n",
      "account Shape: (4500, 4)\n",
      "card Shape: (892, 4)\n",
      "client Shape: (5369, 3)\n",
      "disposition Shape: (5369, 4)\n",
      "district Shape: (77, 16)\n",
      "loan Shape: (682, 7)\n",
      "orders Shape: (6471, 6)\n",
      "transaction Shape: (49498, 9)\n",
      "\n",
      "----- Gretel Synth Data Details ------\n",
      "account Shape: (4500, 4)\n",
      "card Shape: (892, 4)\n",
      "client Shape: (5369, 3)\n",
      "disposition Shape: (5369, 4)\n",
      "district Shape: (77, 16)\n",
      "loan Shape: (682, 7)\n",
      "orders Shape: (6471, 6)\n",
      "transaction Shape: (49498, 9)\n",
      "\n",
      "----- MostlyAI Synth Data Details ------\n",
      "account Shape: (3960, 4)\n",
      "card Shape: (616, 4)\n",
      "client Shape: (6299, 3)\n",
      "disposition Shape: (4730, 4)\n",
      "district Shape: (77, 16)\n",
      "loan Shape: (816, 7)\n",
      "orders Shape: (7823, 6)\n",
      "transaction Shape: (43560, 9)\n",
      "\n",
      "----- YData Synth Data Details ------\n",
      "account Shape: (3908, 4)\n",
      "card Shape: (892, 4)\n",
      "client Shape: (5413, 3)\n",
      "disposition Shape: (5369, 4)\n",
      "district Shape: (77, 16)\n",
      "loan Shape: (90, 7)\n",
      "orders Shape: (5404, 6)\n",
      "transaction Shape: (42986, 9)\n"
     ]
    }
   ],
   "source": [
    "print(\"----- Original Data Details ------\")\n",
    "for table in tables:\n",
    "    print(f\"{table} Shape: {orig_data[table].shape}\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"----- Gretel Synth Data Details ------\")\n",
    "for table in tables:\n",
    "    print(f\"{table} Shape: {gretel_synth_data[table].shape}\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"----- MostlyAI Synth Data Details ------\")\n",
    "for table in tables:\n",
    "    print(f\"{table} Shape: {mostlyai_synth_data[table].shape}\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"----- YData Synth Data Details ------\")\n",
    "for table in tables:\n",
    "    print(f\"{table} Shape: {ydata_synth_data[table].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29600381-9b7c-4c66-bba3-9e033a7e414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_foreign_keys_issues(data:Dict, foreign_key_constraints:List[Dict]):\n",
    "    foreign_key_issues = []\n",
    "    for constraint in foreign_key_constraints:\n",
    "        child, child_column, parent, parent_column = constraint.values()\n",
    "        values_present = data[child][child_column].isin(data[parent][parent_column]).all()\n",
    "        if not values_present:\n",
    "            foreign_key_issues.append(f\"{child}-{parent}\")\n",
    "    return foreign_key_issues\n",
    "\n",
    "def get_primary_keys_issues(data:Dict, primary_key_constraints:List[Dict]):\n",
    "    primary_key_issues = []\n",
    "    for constraint in primary_key_constraints:\n",
    "        table, key_column = constraint.values()\n",
    "        if ydata_synth_data[table].shape[0] != ydata_synth_data[table][key_column].nunique():\n",
    "            primary_key_issues.append(table)\n",
    "    return primary_key_issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33ba4704-7f67-4755-9a8a-86c6c5a2affa",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_key_constraints = [\n",
    "    {'table': 'account', 'key_column': 'account_id' },\n",
    "    {'table': 'card', 'key_column': 'card_id' },\n",
    "    {'table': 'client', 'key_column': 'client_id' },\n",
    "    {'table': 'disposition', 'key_column': 'disposition_id' },\n",
    "    {'table': 'district', 'key_column': 'district_id' },\n",
    "    {'table': 'loan', 'key_column': 'loan_id' },\n",
    "    {'table': 'orders', 'key_column': 'orders_id' },\n",
    "    {'table': 'transaction', 'key_column': 'transaction_id' }\n",
    "]\n",
    "\n",
    "foreign_key_constraints = \\\n",
    "[\n",
    "    {\n",
    "    \"child_table\": \"account\", \n",
    "    \"child_column\": \"district_id\",\n",
    "    \"parent_table\": \"district\", \n",
    "    \"parent_column\": \"district_id\" \n",
    "    },\n",
    "    {\n",
    "    \"child_table\": \"client\", \n",
    "    \"child_column\": \"district_id\",\n",
    "    \"parent_table\": \"district\", \n",
    "    \"parent_column\": \"district_id\" \n",
    "    },\n",
    "    {\n",
    "    \"child_table\": \"disposition\", \n",
    "    \"child_column\": \"account_id\",\n",
    "    \"parent_table\": \"account\", \n",
    "    \"parent_column\": \"account_id\" \n",
    "    },    \n",
    "    {\n",
    "    \"child_table\": \"transaction\", \n",
    "    \"child_column\": \"account_id\",\n",
    "    \"parent_table\": \"account\", \n",
    "    \"parent_column\": \"account_id\" \n",
    "    },\n",
    "    {\n",
    "    \"child_table\": \"loan\", \n",
    "    \"child_column\": \"account_id\",\n",
    "    \"parent_table\": \"account\", \n",
    "    \"parent_column\": \"account_id\" \n",
    "    },\n",
    "    {\n",
    "    \"child_table\": \"orders\", \n",
    "    \"child_column\": \"account_id\",\n",
    "    \"parent_table\": \"account\", \n",
    "    \"parent_column\": \"account_id\" \n",
    "    },\n",
    "    {\n",
    "    \"child_table\": \"disposition\", \n",
    "    \"child_column\": \"client_id\",\n",
    "    \"parent_table\": \"client\", \n",
    "    \"parent_column\": \"client_id\" \n",
    "    },\n",
    "    {\n",
    "    \"child_table\": \"card\", \n",
    "    \"child_column\": \"disposition_id\",\n",
    "    \"parent_table\": \"disposition\", \n",
    "    \"parent_column\": \"disposition_id\" \n",
    "    }                 \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ae8c6bd-ba8d-45aa-b152-d669fc48e2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints = {\n",
    "    \"primary_keys\": 8,\n",
    "    \"foreign_keys\": 8\n",
    "}\n",
    "\n",
    "total_constraints = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48335f72-17e0-496e-8c45-d3b793360ecf",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25870e62-405b-4750-b944-4b15604dd0c3",
   "metadata": {},
   "source": [
    "#### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25eb30fb-5b49-4801-a194-3ba007c9db6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.core.common.random_state(None)\n",
    "seed = 1047\n",
    "ks_seed = 1034"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd039b0b-7757-4d86-b93a-a0b5b3ec62ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_synth(synth_solution:str, original_data:Dict, synth_data:Dict, tables:List, \n",
    "                   primary_key_constraints:List[Dict], foreign_key_constraints:List[Dict], \n",
    "                   total_constraints, verbose = False\n",
    "                  ):\n",
    "    ## Data Integrity\n",
    "    if verbose:\n",
    "        print(f\"---------{synth_solution} Evaluation-----------\")\n",
    "        print(f\"{synth_solution} Constraint Issues Details\")\n",
    "    primary_keys_issues = get_primary_keys_issues(synth_data, primary_key_constraints)\n",
    "    if verbose and primary_keys_issues:\n",
    "        print(f\"Primary Key Issues: {primary_keys_issues}\")\n",
    "    primary_keys_issue_count = len(primary_keys_issues)\n",
    "\n",
    "    foreign_keys_issues = get_foreign_keys_issues(synth_data, foreign_key_constraints)\n",
    "    if verbose and foreign_keys_issues:\n",
    "        print(f\"Foreign Key Issues: {foreign_keys_issues}\")    \n",
    "    foreign_keys_issue_count = len(foreign_keys_issues)\n",
    "    data_integrity_score = 1 - ((primary_keys_issue_count + foreign_keys_issue_count)/total_constraints)\n",
    "    if verbose:\n",
    "        print(f\" -Primary Keys Issues Count: {primary_keys_issue_count}\")\n",
    "        print(f\" -Foreign Keys Issues Count: {foreign_keys_issue_count}\")\n",
    "        print(f\" -Data Integrity Score: {data_integrity_score}\")\n",
    "\n",
    "    genai_eval_scores = []\n",
    "    for table in tables:\n",
    "        # print(table)\n",
    "        orig_df = original_data[table]\n",
    "        synth_df = synth_data[table]\n",
    "\n",
    "        for col in orig_df.columns:\n",
    "            if col in ['date', 'issued']:\n",
    "                orig_df[col] = pd.to_datetime(orig_df[col])\n",
    "                synth_df[col] = pd.to_datetime(synth_df[col])\n",
    "\n",
    "        # Remove id columns\n",
    "        non_id_cols = [col for col in orig_df.columns if not col.endswith('_id')]\n",
    "        orig_df = orig_df[non_id_cols]\n",
    "        synth_df = synth_df[non_id_cols]\n",
    "        cat_columns = orig_df.select_dtypes(exclude=[\"number\",\"bool_\",\"datetime64[ns]\"]).columns.tolist()\n",
    "        # cat_columns = [col for col in cat_columns if not col.endswith('_id')]\n",
    "        # print(f\"Category Cols: {cat_columns}\")\n",
    "        date_columns = orig_df.select_dtypes(include=[\"datetime64[ns]\"]).columns.tolist()\n",
    "        if date_columns:\n",
    "            # print(f\"Date Cols: {date_columns}\")\n",
    "            orig_df = orig_df.drop(date_columns, axis = 1)\n",
    "            synth_df = synth_df.drop(date_columns, axis = 1)\n",
    "        \n",
    "        # Encode Category Columns\n",
    "        if cat_columns:\n",
    "            wrapped_orig, idx_to_key_orig, key_to_idx_orig = wrap_category_columns(orig_df,cat_columns)\n",
    "            wrapped_synth, idx_to_key_synth, key_to_idx_synth = wrap_category_columns(synth_df,cat_columns)\n",
    "        else:\n",
    "            wrapped_orig = orig_df\n",
    "            wrapped_synth = synth_df\n",
    "        # Calculate ECDF\n",
    "        if verbose:\n",
    "            print(\"----Calculating ECDF------\")\n",
    "        query_orig, ecdf_orig, ecdf_synth = \\\n",
    "            multivariate_ecdf(wrapped_orig, \n",
    "                              wrapped_synth, \n",
    "                              n_nodes = 3000, \n",
    "                              verbose = verbose,\n",
    "                              random_seed=ks_seed) \n",
    "\n",
    "        # Calculate KS Stat\n",
    "        ks_stat = ks_statistic(ecdf_orig, ecdf_synth)\n",
    "        \n",
    "        genai_eval_scores.append({\"table\":table, \"eval_score\": ks_stat})\n",
    "    return {\"data_integrity_score\": data_integrity_score, \"eval_scores\": genai_eval_scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d9579f3-b4c8-4af4-b43f-668c70a4870b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gretel Data Integrity Score: 1.0\n",
      "Gretel GenAI Eval Score: 0.270\n"
     ]
    }
   ],
   "source": [
    "gretel_results = evaluate_synth(synth_solution = \"gretel\", \n",
    "                                original_data = orig_data, \n",
    "                                synth_data = gretel_synth_data,\n",
    "                                tables = tables,\n",
    "                                primary_key_constraints = primary_key_constraints,\n",
    "                                foreign_key_constraints = foreign_key_constraints, \n",
    "                                total_constraints = total_constraints,\n",
    "                                verbose=False)\n",
    "print(f\"Gretel Data Integrity Score: {gretel_results['data_integrity_score']}\")\n",
    "print(f\"Gretel GenAI Eval Score: {pd.DataFrame(gretel_results['eval_scores']).eval_score.median():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f219d5fe-2c3a-49ca-82f5-0261b1391ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MostlyAI Data Integrity Score: 1.0\n",
      "MostlyAI GenAI Eval Score: 0.314\n"
     ]
    }
   ],
   "source": [
    "mostlyai_results = evaluate_synth(synth_solution = \"mostlyai\", \n",
    "                                original_data = orig_data, \n",
    "                                synth_data = mostlyai_synth_data,\n",
    "                                tables = tables,\n",
    "                                primary_key_constraints = primary_key_constraints,\n",
    "                                foreign_key_constraints = foreign_key_constraints, \n",
    "                                total_constraints = total_constraints,\n",
    "                                verbose=False)\n",
    "print(f\"MostlyAI Data Integrity Score: {mostlyai_results['data_integrity_score']}\")\n",
    "print(f\"MostlyAI GenAI Eval Score: {pd.DataFrame(mostlyai_results['eval_scores']).eval_score.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7713208-6de0-403e-b856-8e9cec489de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YData Data Integrity Score: 1.0\n",
      "YData GenAI Eval Score: 0.160\n"
     ]
    }
   ],
   "source": [
    "ydata_results = evaluate_synth(synth_solution = \"ydata\", \n",
    "                                original_data = orig_data, \n",
    "                                synth_data = ydata_synth_data,\n",
    "                                tables = tables,\n",
    "                                primary_key_constraints = primary_key_constraints,\n",
    "                                foreign_key_constraints = foreign_key_constraints, \n",
    "                                total_constraints = total_constraints,\n",
    "                                verbose=False)\n",
    "print(f\"YData Data Integrity Score: {ydata_results['data_integrity_score']}\")\n",
    "print(f\"YData GenAI Eval Score: {pd.DataFrame(ydata_results['eval_scores']).eval_score.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9352b90b-ef14-4ee4-b229-f375f6038132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>synth_time</th>\n",
       "      <th>data_integrity_score</th>\n",
       "      <th>genai_eval_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gretel</td>\n",
       "      <td>40 mins</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mostly AI</td>\n",
       "      <td>2 mins</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YData AI</td>\n",
       "      <td>7 mins</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      method synth_time  data_integrity_score  genai_eval_score\n",
       "0     Gretel    40 mins                   1.0              0.28\n",
       "1  Mostly AI     2 mins                   1.0              0.31\n",
       "2   YData AI     7 mins                   1.0              0.16"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gretel_synth_time = \"40 mins\"\n",
    "mostlyai_synth_time = \"2 mins\"\n",
    "ydata_synth_time = \"7 mins\"\n",
    "results = [\n",
    "    {\"method\": \"Gretel\", \"synth_time\": gretel_synth_time, \n",
    "     \"data_integrity_score\": gretel_results['data_integrity_score'], \n",
    "     \"genai_eval_score\": pd.DataFrame(gretel_results['eval_scores']).eval_score.mean().round(2)},\n",
    "    {\"method\": \"Mostly AI\", \"synth_time\": mostlyai_synth_time, \n",
    "     \"data_integrity_score\": mostlyai_results['data_integrity_score'], \n",
    "     \"genai_eval_score\": pd.DataFrame(mostlyai_results['eval_scores']).eval_score.mean().round(2) },\n",
    "    {\"method\": \"YData AI\", \"synth_time\": ydata_synth_time, \n",
    "     \"data_integrity_score\": ydata_results['data_integrity_score'], \n",
    "     \"genai_eval_score\": pd.DataFrame(ydata_results['eval_scores']).eval_score.mean().round(2) }  \n",
    "]\n",
    "\n",
    "pd.DataFrame(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ydata",
   "language": "python",
   "name": "ydata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
